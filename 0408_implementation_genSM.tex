\subsection{Implementation of Generalized Score Matching}
The implementation proceeds very similarly to the Simple Score Matching method. We recall that for the Generalized Score Matching estimator, we have
\begin{gather*}
     \ell(\psi; \mathbf X_1 , \ldots, \mathbf X_n) \\
     = \frac{1}{n}\sum_{v=1}^n \bigg(\!- \kappa\big(\phi(\mathbf X_v)\big)\psi'(\mathbf X_v) - \phi'(\mathbf X_v)\kappa'\big(\phi(\mathbf X_v)\big)\psi(\mathbf X_v) - \frac{1}{2}\kappa\big(\phi(\mathbf X_v)\big)\psi(\mathbf X_v)^2\bigg)
\end{gather*}
so that
\begin{gather*}
    \mathcal L(\theta) = \frac{1}{n}\sum_{v=1}^n \bigg(\!- \kappa\big(\phi(\mathbf X_v)\big)\theta^\tr \varphi'(\mathbf X_v) - \phi'(\mathbf X_v)\kappa'\big(\phi(\mathbf X_v)\big)\theta^\tr \varphi(\mathbf X_v) \\
    - \frac{1}{2}\kappa\big(\phi(\mathbf X_v)\big)\big(\theta^\tr \varphi(\mathbf X_v)\big)^2\bigg) - \lambda_n\,\theta^\tr G_q \theta.
\end{gather*}

For fixed $\theta$, we calculate the gradient and the Hessian of $\mathcal L$ at $\theta$. We have
\begin{gather*}
    \big(\S(\theta)\big)_i = \frac{\partial}{\partial\theta_i} \mathcal L(\theta) = \frac{1}{n}\sum_{v=1}^n \bigg(\!- \kappa\big(\phi(\mathbf X_v)\big)\varphi_i'(\mathbf X_v) - \phi'(\mathbf X_v)\kappa'\big(\phi(\mathbf X_v)\big)\varphi_i(\mathbf X_v) \\
    - \kappa\big(\phi(\mathbf X_v)\big)\varphi_i(\mathbf X_v)\big(\theta^\tr \varphi(\mathbf X_v)\big)\bigg) - 2\lambda_n\big(G_q \theta\big)_i
\end{gather*}
for $i=0,\ldots,m+k$, and
\begin{gather*}
    \big(\H(\theta)\big)_{i,j} = \frac{\partial^2}{\partial\theta_i\partial\theta_j} \mathcal L(\theta) = \frac{1}{n}\sum_{v=1}^n \Big(\!- \kappa\big(\phi(\mathbf X_v)\big)\varphi_i(\mathbf X_v)\varphi_j(\mathbf X_v)\Big) - 2\lambda_n\big(G_q\big)_{i,j},
\end{gather*}
for $i=0,\ldots,m+k$ and $j=0,\ldots,m+k$.

Now, we verify that $\mathcal L$ verifies the hypotheses of \autoref{prop:newton_global_max}. First, we showed that $\mathcal L$ is twice differentiable at every $\theta\in\R^{m+k+1}$.

Let $\theta\in\R^{m+k+1}$. We rewrite the Hessian $\H(\theta)$ as
\begin{equation*}
    \H(\theta) = -\bigg(\frac{1}{n}\sum_{v=1}^n \kappa\big(\phi(\mathbf X_v)\big)\varphi(\mathbf X_v)\varphi(\mathbf X_v)^\tr + 2\lambda_n\,G_q\bigg).
\end{equation*}
Since $\varphi(\mathbf X_v)\varphi(\mathbf X_v)^\tr$ is positive semi-definite for all $v\in{1,\ldots,n}$ and $G_q$ is positive semi-definite, $\H(\theta)$ is negative semi-definite for all $\theta\in\R^{m+k+1}$.