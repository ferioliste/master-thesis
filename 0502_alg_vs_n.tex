\subsection{Algorithm comparison}
In this section, we compare the performance of all five density estimation methods presented. We fix the number of interior knots to $k=10$, as motivated in the previous section, and we consider three sample sizes, $n\in\{100,1000,10000\}$.

Each method is tested on every target density for which its assumptions are satisfied. This yields a total of seven configurations, since two of the methods can be applied to both $f_1$ and $f_2$. For the shifted methods we use $\gamma = 0.05$.

For each configuration and each sample size $n$, we first perform $5$ pilot runs in order to select the penalty parameter $\lambda_n$ by $5$-fold cross-validation, as done in the previous section. After fixing $\lambda_n$, we generate three additional independent samples and fit the estimator on each of them.

The outcomes for the targets $f_1$ and $f_2$ are reported in \autoref{fig:alg_vs_n_f1} and \autoref{fig:alg_vs_n_f2}, respectively.

From these experiments, we make a few considerations. When the target distribution is $f_1$, all methods provide a good approximation of the ground-truth across the three sample sizes considered. The only mehtod that displays a slightly worse behavior is Generalized Score Matching, which seems to behave worse near the boundary of the support. In general, we \linebreak
\begin{figure}[H]
\centering
\includegraphics[width=.9\linewidth]{plots/alg_vs_n_MLE.pdf}
\caption{Comparison of three methods on the target density $f_1$ for $k=10$ and $n\in\{100,1000,10000\}$. The ground-truth density (black) is compared to three estimated densities (colored), obtained from three independent samples.}
\label{fig:alg_vs_n_f1}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=.9\linewidth]{plots/alg_vs_n_SM.pdf}
\caption{Comparison of four methods on the target density $f_2$ for $k=10$ and $n\in\{100,1000,10000\}$. The ground-truth density (black) is compared to three estimated densities (colored), obtained from three independent samples.}
\label{fig:alg_vs_n_f2}
\end{figure}
notice an improvement when increasing $n$ from $100$ to $1000$, but the gain obtained by further increasing the sample size from $1000$ to $10000$ is smaller.

When the target distribution is $f_2$, all methods again provide a good approximation of the ground-truth. However, the score matching based estimators seem to converge to a distribution that is slightly shifted with respect to the ground truth, although this effect becomes less pronounced as $n$ increases. Somewhat surprisingly, the Shifted Maximum Likelihood estimator exhibits the best qualitative behavior, despite the fact of being biased. Finally, again, the improvement between $n=1000$ and $n=10000$ is minor.

In order to compare the quality of the estimations quantitatively, for each configuration and each sample size $n$ we performed an additional $15$ independent tests. For each one, we computed the $L_2$ error between the estimated density and the ground-truth density, and we summarize the results using boxplots of the resulting errors in \autoref{fig:boxplot}. Overall, the error decreases as $n$ increases, as expected. The only exception is the Simple Score Matching estimator, for which the median error slightly increases when passing from $n=1000$ to $n=10000$. Finally, as $n$ grows, the variability of the error also decreases, which we had already noticed in the qualitative plots. \vspace{\baselineskip}

\begin{figure}[hbt]
\centering
\includegraphics[width=.99\linewidth]{plots/boxplots.pdf}
\caption{Boxplots of the $L_2$ error for the seven method-target configurations and $n\in\{100,1000,10000\}$. Each boxplot is computed from $15$ independent repetitions.}
\label{fig:boxplot}
\end{figure}