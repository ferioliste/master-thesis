@misc{huang2021,
    title={Asymptotic Properties of Penalized Spline Estimators in Concave Extended Linear Models: Rates of Convergence}, 
    author={Jianhua Z. Huang and Ya Su},
    year={2021},
    eprint={2105.06367},
    archivePrefix={arXiv},
    primaryClass={math.ST},
    url={https://arxiv.org/abs/2105.06367}, 
}

@book{schumaker_2007,
    place={Cambridge},
    edition={3},
    series={Cambridge Mathematical Library},
    title={Spline Functions: Basic Theory},
    publisher={Cambridge University Press},
    author={Schumaker, Larry},
    year={2007},
    collection={Cambridge Mathematical Library}
}

@article{huang2001,
     ISSN = {10170405, 19968507},
     URL = {http://www.jstor.org/stable/24306816},
     abstract = {Extended linear modeling provides a flexible framework for functional estimation problems with multiple covariates. Such problems include ordinary and generalized regression, density and conditional density estimation, hazard regression, spectral density estimation and polychotomous regression. In this paper, we develop a general theory on the rate of convergence of maximum likelihood estimation in extended linear modeling. The role of concavity of the log-likelihood function is highlighted. Both correctly specified and misspecified models are treated in a unified manner. Applications are made to a variety of structural models: saturated models, partly linear models, and functional ANOVA models. Two specific contexts, counting process regression and conditional density estimation, are used to illustrate the general theory.},
     author = {Jianhua Z. Huang},
     journal = {Statistica Sinica},
     number = {1},
     pages = {173--197},
     publisher = {Institute of Statistical Science, Academia Sinica},
     title = {CONCAVE EXTENDED LINEAR MODELING: A THEORETICAL SYNTHESIS},
     urldate = {2025-10-01},
     volume = {11},
     year = {2001}
}

@book{weinberger,
    author = {Weinberger, Hans F.},
    title = {Variational Methods for Eigenvalue Approximation},
    publisher = {Society for Industrial and Applied Mathematics},
    year = {1974},
    doi = {10.1137/1.9781611970531},
    address = {},
    edition   = {},
    URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970531},
    eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611970531}
}

@article{utreras,
    author = {D., Florencio Utreras},
    title = {Optimal Smoothing of Noisy Data Using Spline Functions},
    journal = {SIAM Journal on Scientific and Statistical Computing},
    volume = {2},
    number = {3},
    pages = {349-362},
    year = {1981},
    doi = {10.1137/0902028},
    URL = {https://doi.org/10.1137/0902028},
    eprint = {https://doi.org/10.1137/0902028},
    abstract = { We consider the problem of approximating a function f supposed to be “smooth”, given its values known with error at n different points of a real interval \$[a,b]\$. To approximate f we use the natural smoothing spline of order q and parameter \$\tau \$. For choosing \$\tau \$, the method of generalized cross validation, proposed by Wahba and others, has very interesting theoretical properties, but requires expensive calculations.The asymptotic behavior of the eigenvalues associated with the spline functions provides a practical method for calculating the GCV function which reduces the computation time by a factor of n. }
}

@book{gu2013,
    author = {Gu, Chong},
    year = {2013},
    month = {01},
    pages = {},
    title = {Smoothing spline ANOVA models},
    volume = {297},
    isbn = {978-1-4614-5368-0},
    journal = {Smoothing Spline ANOVA Models},
    doi = {10.1007/978-1-4614-5369-7}
}

@article{score_matching,
    author = {Hyv\"{a}rinen, Aapo},
    title = {Estimation of Non-Normalized Statistical Models by Score Matching},
    year = {2005},
    issue_date = {12/1/2005},
    publisher = {JMLR.org},
    volume = {6},
    issn = {1532-4435},
    abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
    journal = {J. Mach. Learn. Res.},
    month = dec,
    pages = {695–709},
    numpages = {15}
}